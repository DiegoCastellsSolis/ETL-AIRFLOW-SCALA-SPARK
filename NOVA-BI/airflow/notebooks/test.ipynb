{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          day     type  value_buy  value_sell\n",
      "0  2024-05-10  Oficial      866.0       924.0\n",
      "1  2024-05-10     Blue     1010.0      1040.0\n",
      "2  2024-05-09  Oficial      866.0       924.0\n",
      "3  2024-05-09     Blue     1015.0      1045.0\n",
      "4  2024-05-08  Oficial      866.0       924.0\n"
     ]
    }
   ],
   "source": [
    "url = 'https://api.bluelytics.com.ar/v2/evolution.csv'\n",
    "\n",
    "# Descarga el contenido del CSV\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200:\n",
    "    data = response.text\n",
    "else:\n",
    "    print(\"Error al descargar el CSV:\", response.status_code)\n",
    "    exit()\n",
    "\n",
    "# Procesa el CSV con pandas\n",
    "df = pd.read_csv(io.StringIO(data))\n",
    "\n",
    "# Ahora puedes trabajar con el DataFrame 'df'\n",
    "print(df.head())  # Muestra las primeras filas del DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'daily_dolar' created successfully!\n",
      "Data inserted successfully!\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import os\n",
    "\n",
    "try:\n",
    "    # Replace placeholders with your actual credentials\n",
    "    host = 'localhost'\n",
    "    port = 5432  # Default PostgreSQL port\n",
    "    database = 'staging'\n",
    "    user = 'admin'\n",
    "    password = 'admin' \n",
    "\n",
    "    connection = psycopg2.connect(\n",
    "        host=host,\n",
    "        port=port,\n",
    "        database=database,\n",
    "        user=user,\n",
    "        password=password\n",
    "        )\n",
    "\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    ##############################################3\n",
    "\n",
    "\n",
    "    # Schema (assuming \"staging\" is a schema, not a database)\n",
    "    table_name = 'daily_dolar'\n",
    "\n",
    "    # Check if table exists \n",
    "    check_table_exists = f\"\"\"\n",
    "        SELECT EXISTS (\n",
    "            SELECT 1\n",
    "            FROM information_schema.tables\n",
    "            WHERE table_name = '{table_name}'\n",
    "        );\n",
    "    \"\"\"\n",
    "    cursor.execute(check_table_exists)\n",
    "    exists = cursor.fetchone()[0]  # Get the existence check result\n",
    "\n",
    "    if not exists:  # Create table only if it doesn't exist\n",
    "        create_table = f\"\"\"    \n",
    "        CREATE TABLE {table_name} (\n",
    "            day DATE,     \n",
    "            type VARCHAR(255) NOT NULL,  \n",
    "            value_buy DECIMAL(10,2) NOT NULL,  \n",
    "            value_sell DECIMAL(10,2) NOT NULL,\n",
    "            PRIMARY KEY (day, type)\n",
    "        );\n",
    "        \"\"\"\n",
    "        cursor.execute(create_table)\n",
    "        connection.commit()\n",
    "        print(f\"Table '{table_name}' created successfully!\")\n",
    "\n",
    "    # Assuming your DataFrame (df) has columns matching the table schema\n",
    "    # Prepare data for insertion using list comprehension\n",
    "    data_tuples = [\n",
    "        (row['day'], row['type'], row['value_buy'], row['value_sell'])\n",
    "        for index, row in df.iterrows()\n",
    "    ]\n",
    "\n",
    "    # Insert data in batches (optional for efficiency with large datasets)\n",
    "    insert_query = \"\"\"\n",
    "        INSERT INTO daily_dolar (day, type, value_buy, value_sell)\n",
    "        VALUES (%s, %s, %s, %s)\n",
    "    \"\"\"\n",
    "    cursor.executemany(insert_query, data_tuples)\n",
    "    connection.commit()\n",
    "    ################################################\n",
    " \n",
    "    print(\"Data inserted successfully!\")\n",
    "\n",
    "except (Exception, psycopg2.Error) as error:\n",
    "    print(\"Error while connecting to PostgreSQL\", error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import os\n",
    "from airflow.operators.python_operator import PythonOperator\n",
    "from airflow.hooks.base_hook import BaseHook\n",
    "\n",
    "\n",
    "try:\n",
    "    # Replace placeholders with your actual credentials\n",
    "    staging_conn = BaseHook.get_connection(\"staging\")\n",
    "\n",
    "    connection = psycopg2.connect(\n",
    "        host=staging_conn.host,\n",
    "        port=staging_conn.port,\n",
    "        database=staging_conn.database,\n",
    "        user=staging_conn.user,\n",
    "        password=staging_conn.password\n",
    "        )\n",
    "\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    ##############################################3\n",
    "\n",
    "\n",
    "    # Schema (assuming \"staging\" is a schema, not a database)\n",
    "    table_name = 'daily_dolar'\n",
    "\n",
    "    # Check if table exists \n",
    "    check_table_exists = f\"\"\"\n",
    "        SELECT EXISTS (\n",
    "            SELECT 1\n",
    "            FROM information_schema.tables\n",
    "            WHERE table_name = '{table_name}'\n",
    "        );\n",
    "    \"\"\"\n",
    "    cursor.execute(check_table_exists)\n",
    "    exists = cursor.fetchone()[0]  # Get the existence check result\n",
    "\n",
    "    if not exists:  # Create table only if it doesn't exist\n",
    "        create_table = f\"\"\"    \n",
    "        CREATE TABLE {table_name} (\n",
    "            day DATE,     \n",
    "            type VARCHAR(255) NOT NULL,  \n",
    "            value_buy DECIMAL(10,2) NOT NULL,  \n",
    "            value_sell DECIMAL(10,2) NOT NULL,\n",
    "            PRIMARY KEY (day, type)\n",
    "        );\n",
    "        \"\"\"\n",
    "        cursor.execute(create_table)\n",
    "        connection.commit()\n",
    "        print(f\"Table '{table_name}' created successfully!\")\n",
    "\n",
    "    # Assuming your DataFrame (df) has columns matching the table schema\n",
    "    # Prepare data for insertion using list comprehension\n",
    "    data_tuples = [\n",
    "        (row['day'], row['type'], row['value_buy'], row['value_sell'])\n",
    "        for index, row in df.iterrows()\n",
    "    ]\n",
    "\n",
    "    # Insert data in batches (optional for efficiency with large datasets)\n",
    "    insert_query = \"\"\"\n",
    "        INSERT INTO daily_dolar (day, type, value_buy, value_sell)\n",
    "        VALUES (%s, %s, %s, %s)\n",
    "    \"\"\"\n",
    "    cursor.executemany(insert_query, data_tuples)\n",
    "    connection.commit()\n",
    "    ################################################\n",
    " \n",
    "    print(\"Data inserted successfully!\")\n",
    "\n",
    "except (Exception, psycopg2.Error) as error:\n",
    "    print(\"Error while connecting to PostgreSQL\", error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
