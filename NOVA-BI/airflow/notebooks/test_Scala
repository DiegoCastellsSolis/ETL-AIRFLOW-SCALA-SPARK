



from airflow import DAG
from airflow.operators.bash import BashOperator
from datetime import datetime

# Argumentos por defecto del DAG
default_args = {
    'owner': 'diego castells',
    'depends_on_past': False,
    'start_date': datetime(2023, 10, 1),  # Ajusta si es necesario
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 1
}

# Crear el DAG
dag = DAG(
    'aaa',
    default_args=default_args,
    description='DAG que ejecuta el script df_to_db.scala usando Scala CLI o Spark',
    schedule_interval='@daily',  # Ajusta la frecuencia si es necesario
    catchup=False  # Evitar que ejecute DAGs anteriores
)

# Definir la tarea para ejecutar df_to_db.scala con la ruta correcta
run_scala_script = BashOperator(
    task_id='ORCHESTOR PATIENT CSV TO PARQUET',
    bash_command='spark-submit --class df_parquet --master local[*] /home/diego/Escritorio/NOVA-BI/scala/target/scala-2.12/bi-spark_2.12-0.1.jar',
    dag=dag,
)
run_scala_script